{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec0d05f5",
   "metadata": {},
   "source": [
    "Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Paths\n",
    "raw_data_folder = '/kaggle/input/bci-competition-iv-2a'\n",
    "mat_folder = '/kaggle/input/2a-true-labels/' # Evaluation files Lables\n",
    "# Paths for Cleaned data output\n",
    "cleaned_data_folder_1 = '/kaggle/working/cleaned_data/first_session/'\n",
    "cleaned_data_folder_2 = '/kaggle/working/cleaned_data/second_session/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d296c",
   "metadata": {},
   "source": [
    "Define Preprocessing Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters(raw, l_freq=8, h_freq=30, notch_freq=50):\n",
    "    raw.filter(l_freq=l_freq, h_freq=None, method='fir', fir_design='firwin')\n",
    "    \n",
    "    # (Nyquist frequency= 125 Hz, sfreq=250 Hz)\n",
    "    notch_freqs = [notch_freq, 100] \n",
    "    raw.notch_filter(freqs=notch_freqs, method='fir', fir_design='firwin')\n",
    "    raw.filter(l_freq=None, h_freq=h_freq, method='fir', fir_design='firwin')\n",
    "    \n",
    "    return raw\n",
    "\n",
    "\n",
    "def remove_artifacts(raw, n_components=20):\n",
    "    from mne.preprocessing import ICA\n",
    "    \n",
    "    # Create a copy for ICA fitting\n",
    "    raw_copy = raw.copy()\n",
    "    raw_copy.filter(l_freq=1, h_freq=None)\n",
    "    \n",
    "    # Fit ICA\n",
    "    ica = ICA(n_components=n_components, method='infomax', random_state=42, max_iter=800)\n",
    "    ica.fit(raw_copy)\n",
    "    \n",
    "    # Simplified approach\n",
    "    ica.apply(raw)\n",
    "    \n",
    "    return raw\n",
    "\n",
    "def create_overlapping_epochs(raw, events, event_ids, tmin=0.5, tmax=4.5, overlap=0.25):\n",
    "    all_epochs = []\n",
    "    \n",
    "    # Base epochs\n",
    "    base_epochs = mne.Epochs(raw, events, event_id=event_ids, tmin=tmin, tmax=tmax,\n",
    "                            reject=None, baseline=(tmin, tmin+0.2), preload=True)\n",
    "    all_epochs.append(base_epochs)\n",
    "    \n",
    "    # Create overlapping epochs with different starting points\n",
    "    window_length = tmax - tmin\n",
    "    step_size = window_length * (1 - overlap)\n",
    "    \n",
    "    for shift in np.arange(0.1, 1.0, step_size):\n",
    "        try:\n",
    "            shifted_events = events.copy()\n",
    "            shift_samples = int(shift * raw.info['sfreq'])\n",
    "            shifted_events[:, 0] += shift_samples\n",
    "            \n",
    "            epochs = mne.Epochs(raw, shifted_events, event_id=event_ids,\n",
    "                              tmin=tmin, tmax=tmax, reject=None,\n",
    "                              baseline=(tmin, tmin+0.2), preload=True)\n",
    "            if len(epochs) > 0:\n",
    "                all_epochs.append(epochs)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(all_epochs) > 1:\n",
    "        return mne.concatenate_epochs(all_epochs)\n",
    "    else:\n",
    "        return all_epochs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59fe98",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing - First Session\n",
    "# Create output directory\n",
    "os.makedirs(cleaned_data_folder_1, exist_ok=True)\n",
    "\n",
    "# Get all files in raw_data_folder\n",
    "files = os.listdir(raw_data_folder)\n",
    "\n",
    "# Filter for training GDF files ('T.gdf')\n",
    "filtered_files = [file for file in files if file.endswith('T.gdf')]\n",
    "print(f\"Found {len(filtered_files)} training files\")\n",
    "\n",
    "raw_list = []\n",
    "\n",
    "for file in filtered_files:\n",
    "    print(f\"Processing {file}...\")\n",
    "    file_path = os.path.join(raw_data_folder, file)\n",
    "\n",
    "    # Load raw EEG data\n",
    "    raw = mne.io.read_raw_gdf(file_path, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True)\n",
    "\n",
    "    # Drop EOG channels\n",
    "    raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "\n",
    "    # Apply filtering\n",
    "    raw = apply_filters(raw, l_freq=8, h_freq=30, notch_freq=50)\n",
    "    \n",
    "    # Apply artifact removal\n",
    "    raw = remove_artifacts(raw, n_components=20)\n",
    "\n",
    "    # Save cleaned data\n",
    "    new_file_path = os.path.join(cleaned_data_folder_1, file[:-4] + '.fif')\n",
    "    raw.save(new_file_path, overwrite=True)\n",
    "\n",
    "    raw_list.append(raw)\n",
    "\n",
    "# Concatenate all raw objects into one\n",
    "final_raw = mne.concatenate_raws(raw_list)\n",
    "new_file_path = os.path.join(cleaned_data_folder_1, 'First_Session_Subjects.fif')\n",
    "final_raw.save(new_file_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c82689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract events and epochs for first session\n",
    "events = mne.events_from_annotations(final_raw)\n",
    "print(\"First session events:\", events[1])\n",
    "\n",
    "# Create epochs with overlap for data augmentation\n",
    "epochs = create_overlapping_epochs(final_raw, events[0], event_ids=[7, 8, 9, 10], \n",
    "                                 tmin=0.5, tmax=4.5, overlap=0.25)\n",
    "\n",
    "first_session_data = epochs.get_data(copy=True)\n",
    "first_session_labels = epochs.events[:,-1]\n",
    "\n",
    "print(\"First_session_dataset shape:\", first_session_data.shape)\n",
    "print(\"First session labels distribution:\", np.bincount(first_session_labels - np.min(first_session_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing - Second Session (Evaluation data)\n",
    "# Ensure output folder exists\n",
    "os.makedirs(cleaned_data_folder_2, exist_ok=True)\n",
    "\n",
    "# Filter .E.gdf files\n",
    "gdf_files = [f for f in os.listdir(raw_data_folder) if f.endswith('E.gdf')]\n",
    "mat_files = [f for f in os.listdir(mat_folder) if f.endswith('E.mat')]\n",
    "\n",
    "raw_list = []\n",
    "second_session_labels = np.array([])\n",
    "\n",
    "for file in gdf_files:\n",
    "    print(f\"Processing evaluation file {file}...\")\n",
    "    file_path = os.path.join(raw_data_folder, file)\n",
    "\n",
    "    # Load GDF EEG data\n",
    "    raw = mne.io.read_raw_gdf(file_path, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True)\n",
    "    raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    \n",
    "    # Apply filtering\n",
    "    raw = apply_filters(raw, l_freq=8, h_freq=30, notch_freq=50)\n",
    "    \n",
    "    # Apply artifact removal\n",
    "    raw = remove_artifacts(raw, n_components=20)\n",
    "\n",
    "    # Save cleaned data\n",
    "    new_file_path = os.path.join(cleaned_data_folder_2, file[:-4] + '.fif')\n",
    "    raw.save(new_file_path, overwrite=True)\n",
    "\n",
    "    raw_list.append(raw)\n",
    "\n",
    "    # Load corresponding .mat label file\n",
    "    mat_file_name = file.replace('.gdf', '.mat')\n",
    "    mat_file_path = os.path.join(mat_folder, mat_file_name)\n",
    "    print(f\"data: {file}, label: {mat_file_name}\")\n",
    "\n",
    "    if os.path.exists(mat_file_path):\n",
    "        mat_data = scipy.io.loadmat(mat_file_path)\n",
    "        class_labels = mat_data.get('classlabel', [])\n",
    "\n",
    "        if class_labels is not None and class_labels.size > 0:\n",
    "            class_labels_array = np.array(class_labels, dtype=int).flatten()\n",
    "            second_session_labels = np.concatenate((second_session_labels, class_labels_array))\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: 'classlabel' missing or empty in {mat_file_name}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: {mat_file_name} not found in /kaggle/input/2a-true-labels/\")\n",
    "\n",
    "# Concatenate all raw sessions\n",
    "final_raw = mne.concatenate_raws(raw_list)\n",
    "new_file_path = os.path.join(cleaned_data_folder_2, 'Second_Session_Subjects.fif')\n",
    "final_raw.save(new_file_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract events and epochs for second session\n",
    "events = mne.events_from_annotations(final_raw)\n",
    "print(\"Second session events:\", events[1])\n",
    "\n",
    "epochs = mne.Epochs(final_raw, events[0], event_id=7, tmin=0.5, tmax=4.5, \n",
    "                   reject=None, baseline=(0.5, 0.7), preload=True)\n",
    "second_session_data = epochs.get_data(copy=True)\n",
    "\n",
    "print(\"Second Session Dataset shape:\", second_session_data.shape)\n",
    "print(\"Second session labels distribution:\", np.bincount(second_session_labels.astype(int) - 1))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
