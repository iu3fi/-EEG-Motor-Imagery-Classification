{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb806b3e",
   "metadata": {},
   "source": [
    "Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f777b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive evaluation and analysis\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            main_output, _ = model(data)\n",
    "            probs = F.softmax(main_output, dim=1)\n",
    "            pred = main_output.argmax(dim=1)\n",
    "            \n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(pred.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return np.array(y_true), np.array(y_pred), np.array(y_probs)\n",
    "\n",
    "# Test evaluation\n",
    "y_true, y_pred, y_probs = evaluate_model(model, test_loader, device)\n",
    "test_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f\"\\nFinal Test Results:\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, \n",
    "                          target_names=['Left Hand', 'Right Hand', 'Feet', 'Tongue']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EEG MOTOR IMAGERY CLASSIFICATION RESULTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(f\"Final Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"Best Validation Accuracy: {trainer.best_val_acc:.2f}%\")\n",
    "print(f\"Model Parameters: {trainable_params:,}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Performance summary\n",
    "per_class_acc = [f\"{acc:.1f}%\" for acc in class_accuracies]\n",
    "performance_summary = {\n",
    "    'Overall Accuracy': f\"{test_accuracy*100:.2f}%\",\n",
    "    'Left Hand': per_class_acc[0],\n",
    "    'Right Hand': per_class_acc[1], \n",
    "    'Feet': per_class_acc[2],\n",
    "    'Tongue': per_class_acc[3],\n",
    "    'Mean Confidence': f\"{np.mean(confidence_scores):.3f}\",\n",
    "    'Model Size': f\"{trainable_params:,} parameters\"\n",
    "}\n",
    "\n",
    "print(\"\\nPERFORMANCE BREAKDOWN:\")\n",
    "for key, value in performance_summary.items():\n",
    "    print(f\"{key:.<20} {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe99d6",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Visualization and analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Training history\n",
    "axes[0, 0].plot(history['train_losses'], label='Train Loss', alpha=0.7)\n",
    "axes[0, 0].plot(history['val_losses'], label='Val Loss', alpha=0.7)\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "axes[0, 1].plot(history['train_accs'], label='Train Acc', alpha=0.7)\n",
    "axes[0, 1].plot(history['val_accs'], label='Val Acc', alpha=0.7)\n",
    "axes[0, 1].set_title('Training and Validation Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# 2. Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Left Hand', 'Right Hand', 'Feet', 'Tongue'],\n",
    "            yticklabels=['Left Hand', 'Right Hand', 'Feet', 'Tongue'],\n",
    "            ax=axes[0, 2])\n",
    "axes[0, 2].set_title('Confusion Matrix')\n",
    "axes[0, 2].set_ylabel('True Label')\n",
    "axes[0, 2].set_xlabel('Predicted Label')\n",
    "\n",
    "# 3. Class-wise accuracy\n",
    "class_accuracies = []\n",
    "for i in range(4):\n",
    "    class_mask = y_true == i\n",
    "    if np.sum(class_mask) > 0:\n",
    "        class_acc = accuracy_score(y_true[class_mask], y_pred[class_mask])\n",
    "        class_accuracies.append(class_acc * 100)\n",
    "    else:\n",
    "        class_accuracies.append(0)\n",
    "\n",
    "class_names = ['Left Hand', 'Right Hand', 'Feet', 'Tongue']\n",
    "bars = axes[1, 0].bar(class_names, class_accuracies, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "axes[1, 0].set_title('Class-wise Accuracy')\n",
    "axes[1, 0].set_ylabel('Accuracy (%)')\n",
    "axes[1, 0].set_ylim([0, 100])\n",
    "for bar, acc in zip(bars, class_accuracies):\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                    f'{acc:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "# 4. Prediction confidence distribution\n",
    "confidence_scores = np.max(y_probs, axis=1)\n",
    "axes[1, 1].hist(confidence_scores, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[1, 1].set_title('Prediction Confidence Distribution')\n",
    "axes[1, 1].set_xlabel('Confidence Score')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].axvline(np.mean(confidence_scores), color='red', linestyle='--', \n",
    "                   label=f'Mean: {np.mean(confidence_scores):.3f}')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# 5. Feature importance analysis (Simplified approach)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_input = X_test[:10].to(device)\n",
    "    main_output, _ = model(sample_input)\n",
    "    feature_importance = torch.mean(torch.abs(main_output), dim=0).cpu().numpy()\n",
    "\n",
    "axes[1, 2].bar(class_names, feature_importance, color=['#FF9999', '#66B2FF', '#99FF99', '#FFCC99'])\n",
    "axes[1, 2].set_title('Average Feature Activation by Class')\n",
    "axes[1, 2].set_ylabel('Activation Magnitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('enhanced_eeg_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AUC Evaluation ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AUC EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    macro_auc_score = roc_auc_score(y_true, y_probs, multi_class='ovr', average='macro')\n",
    "    weighted_auc_score = roc_auc_score(y_true, y_probs, multi_class='ovr', average='weighted')\n",
    "    print(f\"Macro-averaged AUC (One-vs-Rest): {macro_auc_score:.4f}\")\n",
    "    print(f\"Weighted-averaged AUC (One-vs-Rest): {weighted_auc_score:.4f}\")\n",
    "\n",
    "    # Plotting ROC curves for each class\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    class_names = ['Left Hand', 'Right Hand', 'Feet', 'Tongue'] \n",
    "\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        # Compute ROC curve and AUC for each class\n",
    "        fpr, tpr, _ = roc_curve(y_true == i, y_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve for {class_name} (area = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance level (AUC = 0.5)')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve - One-vs-Rest')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig('multi_class_roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"Could not compute AUC score or plot ROC curve: {e}\")\n",
    "    print(\"This typically happens if a class has only one sample, or if predictions are all the same for a class.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
