{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc62a53",
   "metadata": {},
   "source": [
    "**Channel Grouping**\n",
    "𝑠^[𝑙]   : Channels in the left hemisphere\n",
    "𝑠^[𝑟]   : Corresponding channels in the right hemisphere\n",
    "𝑠^[𝑚]   : Channels in the midline region\n",
    "\n",
    "**Hemispheric Difference Computation**\n",
    "For each pair of corresponding left and right hemisphere channels (j ∈ [1,〖 𝑙〗_𝑔]), calculate the difference.\n",
    "ⅆ_𝑗=𝑠_𝑖^[𝑙] −𝑠_𝑗^[𝑟] \n",
    "\n",
    "**Final Feature Construction**\n",
    "The set of all hemispheric differences (D = [ⅆ_𝑗]) is concatenated with midline signals 𝑠^[𝑚] , and the final feature vector is computed as:\n",
    "𝑋=[𝐷^𝑇 𝑠^[𝑚]𝑇 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70600614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Normalize labels to [0, 1, 2, 3]\n",
    "y_train = first_session_labels - np.min(first_session_labels)\n",
    "y_test = second_session_labels - np.min(second_session_labels)\n",
    "\n",
    "print(f\"First session data shape: {first_session_data.shape}\")\n",
    "print(f\"Second session data shape: {second_session_data.shape}\")\n",
    "\n",
    "# EEG channel renaming\n",
    "EEG_CH_NAMES = [          \n",
    "    \"Fz\",\"FC3\",\"FC1\",\"FCz\",\"FC2\",\"FC4\",\n",
    "    \"C5\",\"C3\",\"C1\",\"Cz\",\"C2\",\"C4\",\"C6\",\n",
    "    \"CP3\",\"CP1\",\"CPz\",\"CP2\",\"CP4\",\n",
    "    \"P1\",\"Pz\",\"P2\",\"POz\"\n",
    "]\n",
    "\n",
    "LEFT_CHS     = [\"FC3\", \"FC1\", \"C5\", \"C3\", \"C1\", \"CP3\", \"CP1\", \"P1\"]\n",
    "RIGHT_CHS    = [\"FC4\", \"FC2\", \"C6\", \"C4\", \"C2\", \"CP4\", \"CP2\", \"P2\"]\n",
    "MIDLINE_CHS  = [\"Fz\", \"FCz\", \"Cz\", \"CPz\", \"Pz\", \"POz\"]\n",
    "\n",
    "def get_channel_indices(ch_names, full_list):\n",
    "    return [full_list.index(ch) for ch in ch_names]\n",
    "\n",
    "idx_l = get_channel_indices(LEFT_CHS, EEG_CH_NAMES)\n",
    "idx_r = get_channel_indices(RIGHT_CHS, EEG_CH_NAMES)\n",
    "idx_m = get_channel_indices(MIDLINE_CHS, EEG_CH_NAMES)\n",
    "\n",
    "# Region-level feature extraction\n",
    "def extract_region_features(data):\n",
    "    D = data[:, idx_l, :] - data[:, idx_r, :]\n",
    "    M = data[:, idx_m, :]\n",
    "    return np.concatenate([D, M], axis=1)\n",
    "\n",
    "# Apply region-level extraction\n",
    "X_first_region = extract_region_features(first_session_data)\n",
    "X_second_region = extract_region_features(second_session_data)\n",
    "\n",
    "print(f\"Region-level feature shape: {X_first_region.shape}\")\n",
    "\n",
    "# Robust normalization\n",
    "def robust_normalize(data):\n",
    "    normalized_data = np.zeros_like(data)\n",
    "    for trial in range(data.shape[0]):\n",
    "        for channel in range(data.shape[1]):\n",
    "            channel_data = data[trial, channel, :]\n",
    "            median = np.median(channel_data)\n",
    "            mad = np.median(np.abs(channel_data - median))\n",
    "            if mad > 0:\n",
    "                normalized_data[trial, channel, :] = (channel_data - median) / (1.4826 * mad)\n",
    "            else:\n",
    "                normalized_data[trial, channel, :] = channel_data - median\n",
    "    return normalized_data\n",
    "\n",
    "X_first_session = robust_normalize(X_first_region)\n",
    "X_second_session = robust_normalize(X_second_region)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
